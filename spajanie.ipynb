{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=spark.read.format('csv').options(header='true', inferSchema='true').load('C:/Users/User/Desktop/Accidents.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=spark.read.format('csv').options(header='true', inferSchema='true').load('C:/Users/User/Desktop/Vehicles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=spark.read.format('csv').options(header='true', inferSchema='true').load('C:/Users/User/Desktop/Casualties.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1=data1.withColumnRenamed(\"Accident_Index\",\"ID\")\n",
    "data2=data2.withColumnRenamed(\"Accident_Index\",\"IDE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge = data.join(data1, data.Accident_Index == data1.ID)\n",
    "merge.drop(\"ID\")\n",
    "full_merge = merge.join(data2, merge.Accident_Index == data2.IDE)\n",
    "full_merge=full_merge.drop(\"IDE\")\n",
    "full_merge=full_merge.drop(\"ID\")\n",
    "len(full_merge.columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when\n",
    "newsdf = full_merge.withColumn(\"Accident_Severity\", when(full_merge[\"Accident_Severity\"] == 3, 2).otherwise(full_merge[\"Accident_Severity\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsdf.registerTempTable(\"TempTable\")\n",
    "mrtvy = sqlContext.sql('SELECT * FROM TempTable WHERE Accident_Severity = 1')\n",
    "#mrtvy_pocet = mrtvy.count()\n",
    "nemrtvy = sqlContext.sql('SELECT * FROM TempTable WHERE Accident_Severity = 2')\n",
    "#nemrtvy_pocet = nemrtvy.count()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vzorka_mrtvy = mrtvy.sampleBy(\"Accident_Severity\", fractions = {1: 0.05}, seed = 0)\n",
    "vzorka_nemrtvy = nemrtvy.sampleBy(\"Accident_Severity\", fractions = {2: 0.05}, seed = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------+\n",
      "|Accident_Severity| count|\n",
      "+-----------------+------+\n",
      "|                2|210374|\n",
      "+-----------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "groupZeros = vzorka_nemrtvy.groupBy(\"Accident_Severity\").count().orderBy(\"Accident_Severity\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4203"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vzorka_mrtvy.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vzorka_cela = vzorka_mrtvy.union(vzorka_nemrtvy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214577"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vzorka_cela.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vzorka_cela.describe(\"Age_of_Vehicle\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean as _mean, col\n",
    "\n",
    "df_stats = vzorka_cela.select(\n",
    "    _mean(col('Age_of_Driver')).alias('mean')).collect()\n",
    "\n",
    "mean = df_stats[0]['mean']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  _1|                  _2|\n",
      "+--------------------+--------------------+\n",
      "|   Accident_Severity|                 1.0|\n",
      "|  Number_of_Vehicles| -0.0636911069269698|\n",
      "|Number_of_Casualties|  -0.120666368557851|\n",
      "|     Junction_Detail|0.051871110687382205|\n",
      "|    Junction_Control| 0.07414108021980692|\n",
      "|Did_Police_Office...| 0.05657186361984509|\n",
      "|   Junction_Location| 0.05314717297823542|\n",
      "|Skidding_and_Over...|-0.05192407596094772|\n",
      "|Hit_Object_off_Ca...|-0.05299760866808702|\n",
      "|   Casualty_Severity| 0.42392624071726726|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names = vzorka_cela.schema.names\n",
    "t = zip(names,correlations)\n",
    "#print(t)\n",
    "#print(\"-------------------\")\n",
    "tt = spark.createDataFrame(t)\n",
    "#tt.show()\n",
    "\n",
    "tt.registerTempTable(\"TempTable\")\n",
    "atributy_table = sqlContext.sql('SELECT * FROM TempTable WHERE _2 > 0.05 OR _2 <-0.05')\n",
    "atributy = atributy_table.select(\"_2\")\n",
    "atributy_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "bezprazdnych = vzorka_cela.withColumn(\"Age_of_Driver\", when(vzorka_cela[\"Age_of_Driver\"] == -1, mean).otherwise(vzorka_cela[\"Age_of_Driver\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vzorka_cela   = vzorka_cela.drop(\"Location_Easting_OSGR\",\n",
    "\t\t\t\t\t \"Location_Northing_OSGR\",\n",
    "\t\t\t\t\t\"Longitude\",\n",
    "\t\t\t\t\t \"Latitude\",\n",
    "\t\t\t\t\t \"Local_Authority_(District)\",\n",
    "\t\t\t\t\t \"1st_Road_Class\",\n",
    "\t\t\t\t\t \"1st_Road_Number\",\n",
    "\t\t\t\t\t \"Road_Type\",\n",
    "\t\t\t\t\t \"Speed_limit\",\n",
    "\t\t\t\t\t \"2nd_Road_Class\",\n",
    "\t\t\t\t\t \"2nd_Road_Number\",\n",
    "\t\t\t\t\t\"Pedestrian_Crossing-Human_Control\",\n",
    "\t\t\t\t\t\"Pedestrian_Crossing-Physical_Facilities\",\n",
    "\t\t\t\t\t \"Special_Conditions_at_Site\",\n",
    "\t\t\t\t\t \"Carriageway_Hazards\",\n",
    "\t\t\t\t\t \"Urban_or_Rural_Area\",\n",
    "\t\t\t\t\t \"Vehicle_Reference\",\n",
    "\t\t\t\t\t \"Towing_and_Articulation\",\n",
    "\t\t\t\t\t \"Vehicle_Manoeuvre\",\n",
    "\t\t\t\t\t\"Vehicle_Location-Restricted_Lane\",\n",
    "\t\t\t\t\t \"Vehicle_Leaving_Carriageway\",\n",
    "\t\t\t\t\t \"Was_Vehicle_Left_Hand_Drive?\",\n",
    "\t\t\t\t\t \"Journey_Purpose_of_Driver\",\n",
    "\t\t\t\t\t \"Propulsion_Code\",\n",
    "\t\t\t\t\t \"Driver_IMD_Decile\",\n",
    "\t\t\t\t\t \"Driver_Home_Area_Type\",\n",
    "\t\t\t\t\t\"Vehicle_Reference\",\n",
    "\t\t\t\t\t \"Casualty_Reference\",\n",
    "\t\t\t\t\t \"Police_Force\",\n",
    "                    \"Day_of_Week\",\n",
    "                                 \"Light_Conditions\",\n",
    "                                 \"Weather_Conditions\",\n",
    "                                 \"Road_Surface_Conditions\",\n",
    "                                 \"Vehicle_Type\",\n",
    "                                 \"Hit_Object_in_Carriageway\",\n",
    "                                 \"1st_Point_of_Impact\",\n",
    "                                 \"Sex_of_Driver\",\n",
    "                                 \"Age_of_Driver\",\n",
    "                                 \"Age_Band_of_Driver\",\n",
    "                                 \"Engine_Capacity_(CC)\",\n",
    "                                 \"Age_of_Vehicle\",\n",
    "                                 \"Casualty_Class\",\n",
    "                                 \"Sex_of_Casualty\",\n",
    "                                 \"Age_of_Casualty\",\n",
    "                                 \"Age_Band_of_Casualty\",\n",
    "                                 \"Casualty_Severity\",\n",
    "                                 \"Pedestrian_Location\",\n",
    "                                 \"Pedestrian_Movement\",\n",
    "                                 \"Car_Passenger\",\n",
    "                                 \"Bus_or_Coach_Passenger\",\n",
    "                                 \"Pedestrian_Road_Maintenance_Worker\",\n",
    "                                 \"Casualty_Type\",\n",
    "                                 \"Casualty_Home_Area_Type\",\n",
    "\t\t\t\t\t )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Accident_Severity=1, Number_of_Vehicles=2, Number_of_Casualties=3, Junction_Detail=0, Junction_Control=-1, Did_Police_Officer_Attend_Scene_of_Accident=1, Junction_Location=0, Skidding_and_Overturning=0, Hit_Object_off_Carriageway=0)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vzorka_cela.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***************          DESICION TREE             ***************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-cfd1a06acef1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtree_classifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeaturesCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"features\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Accident_Severity\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimpurity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"entropy\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxDepth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxBins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtree_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\base.pyc\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\wrapper.pyc\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\wrapper.pyc\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \"\"\"\n\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print \"***************          DESICION TREE             ***************\"\n",
    "from pyspark.ml.classification import DecisionTreeClassifier, DecisionTreeClassificationModel\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vector_data = VectorAssembler(inputCols=[\"Number_of_Vehicles\", \"Number_of_Casualties\", \"Junction_Detail\", \"Junction_Control\", \"Did_Police_Officer_Attend_Scene_of_Accident\", \"Junction_Location\",\"Skidding_and_Overturning\",\"Hit_Object_off_Carriageway\"],\n",
    "        outputCol=\"features\").transform(vzorka_cela)\n",
    "training_data, test_data = vector_data.randomSplit([0.7, 0.3], seed=123)\n",
    " \n",
    "tree_classifier = DecisionTreeClassifier(featuresCol=\"features\",labelCol=\"Accident_Severity\",impurity=\"entropy\",maxDepth=10, maxBins=100) \n",
    " \n",
    "tree_model = tree_classifier.fit(training_data)\n",
    " \n",
    "predictions = tree_model.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassificationModel (uid=DecisionTreeClassifier_42d09731784afb4bc376) of depth 10 with 767 nodes\n",
      "  If (feature 1 <= 3.0)\n",
      "   If (feature 4 <= 1.0)\n",
      "    If (feature 3 <= 0.0)\n",
      "     If (feature 1 <= 1.0)\n",
      "      If (feature 0 <= 1.0)\n",
      "       If (feature 6 <= 1.0)\n",
      "        If (feature 7 <= 3.0)\n",
      "         If (feature 5 <= -1.0)\n",
      "          If (feature 7 <= 0.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 0.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 5 > -1.0)\n",
      "          If (feature 7 <= 2.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 2.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 7 > 3.0)\n",
      "         If (feature 7 <= 4.0)\n",
      "          If (feature 3 <= -1.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 3 > -1.0)\n",
      "           If (feature 5 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > -1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 7 > 4.0)\n",
      "          If (feature 7 <= 5.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 7 > 5.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "       Else (feature 6 > 1.0)\n",
      "        If (feature 7 <= 0.0)\n",
      "         If (feature 6 <= 2.0)\n",
      "          If (feature 3 <= -1.0)\n",
      "           If (feature 2 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 3 > -1.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 6 > 2.0)\n",
      "          Predict: 2.0\n",
      "        Else (feature 7 > 0.0)\n",
      "         If (feature 7 <= 1.0)\n",
      "          If (feature 6 <= 2.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 2.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 7 > 1.0)\n",
      "          If (feature 7 <= 2.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 7 > 2.0)\n",
      "           If (feature 7 <= 4.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 4.0)\n",
      "            Predict: 2.0\n",
      "      Else (feature 0 > 1.0)\n",
      "       If (feature 0 <= 2.0)\n",
      "        If (feature 6 <= 0.0)\n",
      "         If (feature 7 <= 0.0)\n",
      "          If (feature 3 <= -1.0)\n",
      "           If (feature 5 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 3 > -1.0)\n",
      "           If (feature 5 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > -1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 7 > 0.0)\n",
      "          If (feature 7 <= 4.0)\n",
      "           If (feature 7 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 3.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 4.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 6 > 0.0)\n",
      "         If (feature 2 <= 0.0)\n",
      "          If (feature 7 <= 10.0)\n",
      "           If (feature 6 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 10.0)\n",
      "           If (feature 6 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 2 > 0.0)\n",
      "          If (feature 5 <= 1.0)\n",
      "           If (feature 5 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 0.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 5 > 1.0)\n",
      "           Predict: 2.0\n",
      "       Else (feature 0 > 2.0)\n",
      "        If (feature 0 <= 4.0)\n",
      "         If (feature 6 <= 0.0)\n",
      "          If (feature 7 <= 9.0)\n",
      "           If (feature 7 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 7.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 9.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 6 > 0.0)\n",
      "          If (feature 7 <= 0.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 0.0)\n",
      "           If (feature 7 <= 9.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 9.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 0 > 4.0)\n",
      "         If (feature 7 <= 0.0)\n",
      "          If (feature 0 <= 6.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 6.0)\n",
      "           If (feature 0 <= 9.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 9.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 7 > 0.0)\n",
      "          Predict: 2.0\n",
      "     Else (feature 1 > 1.0)\n",
      "      If (feature 7 <= 0.0)\n",
      "       If (feature 6 <= 2.0)\n",
      "        If (feature 1 <= 2.0)\n",
      "         If (feature 0 <= 5.0)\n",
      "          If (feature 6 <= 0.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 0.0)\n",
      "           If (feature 5 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 1.0)\n",
      "            Predict: 1.0\n",
      "         Else (feature 0 > 5.0)\n",
      "          If (feature 0 <= 8.0)\n",
      "           If (feature 0 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 7.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 8.0)\n",
      "           Predict: 2.0\n",
      "        Else (feature 1 > 2.0)\n",
      "         If (feature 0 <= 7.0)\n",
      "          If (feature 5 <= -1.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 5 > -1.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 0 > 7.0)\n",
      "          If (feature 3 <= -1.0)\n",
      "           If (feature 0 <= 9.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 9.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 3 > -1.0)\n",
      "           If (feature 0 <= 9.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 9.0)\n",
      "            Predict: 1.0\n",
      "       Else (feature 6 > 2.0)\n",
      "        If (feature 0 <= 1.0)\n",
      "         If (feature 1 <= 2.0)\n",
      "          Predict: 2.0\n",
      "         Else (feature 1 > 2.0)\n",
      "          If (feature 3 <= -1.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 3 > -1.0)\n",
      "           Predict: 2.0\n",
      "        Else (feature 0 > 1.0)\n",
      "         If (feature 1 <= 2.0)\n",
      "          If (feature 0 <= 2.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 2.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 1 > 2.0)\n",
      "          If (feature 6 <= 3.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 3.0)\n",
      "           If (feature 5 <= -1.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 5 > -1.0)\n",
      "            Predict: 2.0\n",
      "      Else (feature 7 > 0.0)\n",
      "       If (feature 7 <= 4.0)\n",
      "        If (feature 1 <= 2.0)\n",
      "         If (feature 0 <= 6.0)\n",
      "          If (feature 0 <= 3.0)\n",
      "           If (feature 6 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 3.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 0 > 6.0)\n",
      "          If (feature 3 <= -1.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 3 > -1.0)\n",
      "           Predict: 1.0\n",
      "        Else (feature 1 > 2.0)\n",
      "         If (feature 5 <= -1.0)\n",
      "          Predict: 1.0\n",
      "         Else (feature 5 > -1.0)\n",
      "          If (feature 7 <= 3.0)\n",
      "           If (feature 0 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 2.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 3.0)\n",
      "           If (feature 6 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 1.0)\n",
      "            Predict: 2.0\n",
      "       Else (feature 7 > 4.0)\n",
      "        If (feature 0 <= 1.0)\n",
      "         If (feature 7 <= 7.0)\n",
      "          If (feature 7 <= 6.0)\n",
      "           If (feature 1 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 2.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 6.0)\n",
      "           If (feature 6 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 7 > 7.0)\n",
      "          If (feature 5 <= -1.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 5 > -1.0)\n",
      "           If (feature 6 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 2.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 0 > 1.0)\n",
      "         If (feature 7 <= 7.0)\n",
      "          If (feature 6 <= 1.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 1.0)\n",
      "           If (feature 1 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 2.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 7 > 7.0)\n",
      "          If (feature 0 <= 5.0)\n",
      "           If (feature 7 <= 9.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 9.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 5.0)\n",
      "           If (feature 1 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 2.0)\n",
      "            Predict: 2.0\n",
      "    Else (feature 3 > 0.0)\n",
      "     If (feature 7 <= 0.0)\n",
      "      If (feature 2 <= 2.0)\n",
      "       If (feature 0 <= 1.0)\n",
      "        If (feature 5 <= 2.0)\n",
      "         Predict: 2.0\n",
      "        Else (feature 5 > 2.0)\n",
      "         If (feature 6 <= 1.0)\n",
      "          If (feature 2 <= 1.0)\n",
      "           If (feature 3 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > 3.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 2 > 1.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 6 > 1.0)\n",
      "          Predict: 2.0\n",
      "       Else (feature 0 > 1.0)\n",
      "        If (feature 6 <= 1.0)\n",
      "         If (feature 5 <= 3.0)\n",
      "          If (feature 0 <= 4.0)\n",
      "           If (feature 1 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 2.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 4.0)\n",
      "           If (feature 2 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 5 > 3.0)\n",
      "          If (feature 1 <= 2.0)\n",
      "           If (feature 5 <= 4.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 4.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 1 > 2.0)\n",
      "           If (feature 5 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 7.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 6 > 1.0)\n",
      "         If (feature 1 <= 2.0)\n",
      "          Predict: 2.0\n",
      "         Else (feature 1 > 2.0)\n",
      "          If (feature 3 <= 2.0)\n",
      "           Predict: 1.0\n",
      "          Else (feature 3 > 2.0)\n",
      "           If (feature 5 <= 2.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 5 > 2.0)\n",
      "            Predict: 2.0\n",
      "      Else (feature 2 > 2.0)\n",
      "       If (feature 1 <= 1.0)\n",
      "        If (feature 0 <= 1.0)\n",
      "         If (feature 2 <= 6.0)\n",
      "          If (feature 5 <= 5.0)\n",
      "           If (feature 5 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 5 > 5.0)\n",
      "           If (feature 5 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 7.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 2 > 6.0)\n",
      "          If (feature 5 <= 5.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 5 > 5.0)\n",
      "           If (feature 2 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 7.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 0 > 1.0)\n",
      "         If (feature 3 <= 3.0)\n",
      "          If (feature 2 <= 3.0)\n",
      "           If (feature 5 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 7.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 2 > 3.0)\n",
      "           If (feature 2 <= 8.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 8.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 3 > 3.0)\n",
      "          If (feature 0 <= 2.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 2.0)\n",
      "           If (feature 2 <= 6.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 6.0)\n",
      "            Predict: 2.0\n",
      "       Else (feature 1 > 1.0)\n",
      "        If (feature 6 <= 0.0)\n",
      "         If (feature 3 <= 2.0)\n",
      "          If (feature 0 <= 1.0)\n",
      "           If (feature 5 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 2.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 1.0)\n",
      "           If (feature 1 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 2.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 3 > 2.0)\n",
      "          If (feature 0 <= 5.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 5.0)\n",
      "           If (feature 5 <= 5.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 5.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 6 > 0.0)\n",
      "         If (feature 3 <= 1.0)\n",
      "          If (feature 1 <= 2.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 1 > 2.0)\n",
      "           If (feature 0 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 1.0)\n",
      "            Predict: 1.0\n",
      "         Else (feature 3 > 1.0)\n",
      "          If (feature 6 <= 4.0)\n",
      "           If (feature 3 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > 2.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 4.0)\n",
      "           If (feature 1 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 2.0)\n",
      "            Predict: 2.0\n",
      "     Else (feature 7 > 0.0)\n",
      "      If (feature 1 <= 2.0)\n",
      "       If (feature 2 <= 2.0)\n",
      "        If (feature 5 <= 7.0)\n",
      "         If (feature 5 <= 1.0)\n",
      "          If (feature 7 <= 9.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 7 > 9.0)\n",
      "           If (feature 1 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 5 > 1.0)\n",
      "          Predict: 2.0\n",
      "        Else (feature 5 > 7.0)\n",
      "         If (feature 6 <= 2.0)\n",
      "          If (feature 0 <= 2.0)\n",
      "           If (feature 7 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 2.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 2.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 1.0\n",
      "         Else (feature 6 > 2.0)\n",
      "          If (feature 7 <= 1.0)\n",
      "           If (feature 1 <= 1.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 1 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 1.0)\n",
      "           Predict: 2.0\n",
      "       Else (feature 2 > 2.0)\n",
      "        If (feature 0 <= 4.0)\n",
      "         If (feature 2 <= 5.0)\n",
      "          If (feature 6 <= 2.0)\n",
      "           If (feature 1 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 2.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 2 > 5.0)\n",
      "          If (feature 6 <= 0.0)\n",
      "           If (feature 5 <= 5.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 5.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 0.0)\n",
      "           If (feature 5 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 1.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 0 > 4.0)\n",
      "         If (feature 7 <= 4.0)\n",
      "          If (feature 5 <= 1.0)\n",
      "           If (feature 0 <= 5.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 0 > 5.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 5 > 1.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 7 > 4.0)\n",
      "          Predict: 2.0\n",
      "      Else (feature 1 > 2.0)\n",
      "       If (feature 5 <= 1.0)\n",
      "        If (feature 6 <= 1.0)\n",
      "         If (feature 2 <= 7.0)\n",
      "          If (feature 7 <= 3.0)\n",
      "           If (feature 2 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 3.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 3.0)\n",
      "           If (feature 0 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 2 > 7.0)\n",
      "          Predict: 2.0\n",
      "        Else (feature 6 > 1.0)\n",
      "         If (feature 0 <= 1.0)\n",
      "          If (feature 7 <= 4.0)\n",
      "           If (feature 2 <= 8.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 8.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 7 > 4.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 0 > 1.0)\n",
      "          If (feature 6 <= 3.0)\n",
      "           If (feature 7 <= 6.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 6.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 6 > 3.0)\n",
      "           Predict: 2.0\n",
      "       Else (feature 5 > 1.0)\n",
      "        If (feature 2 <= 6.0)\n",
      "         If (feature 0 <= 3.0)\n",
      "          If (feature 6 <= 2.0)\n",
      "           If (feature 7 <= 9.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 9.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 2.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 0 > 3.0)\n",
      "          If (feature 7 <= 1.0)\n",
      "           Predict: 1.0\n",
      "          Else (feature 7 > 1.0)\n",
      "           Predict: 2.0\n",
      "        Else (feature 2 > 6.0)\n",
      "         Predict: 2.0\n",
      "   Else (feature 4 > 1.0)\n",
      "    If (feature 7 <= 0.0)\n",
      "     If (feature 0 <= 1.0)\n",
      "      If (feature 3 <= -1.0)\n",
      "       Predict: 2.0\n",
      "      Else (feature 3 > -1.0)\n",
      "       If (feature 5 <= 2.0)\n",
      "        If (feature 2 <= 3.0)\n",
      "         If (feature 3 <= 3.0)\n",
      "          If (feature 2 <= 0.0)\n",
      "           If (feature 1 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 2 > 0.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 3 > 3.0)\n",
      "          If (feature 2 <= 2.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 2 > 2.0)\n",
      "           If (feature 1 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 1.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 2 > 3.0)\n",
      "         Predict: 2.0\n",
      "       Else (feature 5 > 2.0)\n",
      "        Predict: 2.0\n",
      "     Else (feature 0 > 1.0)\n",
      "      If (feature 6 <= 2.0)\n",
      "       If (feature 0 <= 4.0)\n",
      "        If (feature 2 <= 3.0)\n",
      "         If (feature 0 <= 2.0)\n",
      "          If (feature 2 <= 2.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 2 > 2.0)\n",
      "           If (feature 1 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 0 > 2.0)\n",
      "          If (feature 3 <= -1.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 3 > -1.0)\n",
      "           Predict: 2.0\n",
      "        Else (feature 2 > 3.0)\n",
      "         Predict: 2.0\n",
      "       Else (feature 0 > 4.0)\n",
      "        If (feature 1 <= 1.0)\n",
      "         If (feature 3 <= -1.0)\n",
      "          If (feature 0 <= 5.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 0 > 5.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 3 > -1.0)\n",
      "          Predict: 2.0\n",
      "        Else (feature 1 > 1.0)\n",
      "         Predict: 2.0\n",
      "      Else (feature 6 > 2.0)\n",
      "       If (feature 1 <= 1.0)\n",
      "        Predict: 2.0\n",
      "       Else (feature 1 > 1.0)\n",
      "        If (feature 2 <= 3.0)\n",
      "         Predict: 2.0\n",
      "        Else (feature 2 > 3.0)\n",
      "         If (feature 1 <= 2.0)\n",
      "          If (feature 5 <= 2.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 5 > 2.0)\n",
      "           Predict: 1.0\n",
      "         Else (feature 1 > 2.0)\n",
      "          Predict: 2.0\n",
      "    Else (feature 7 > 0.0)\n",
      "     If (feature 0 <= 1.0)\n",
      "      Predict: 2.0\n",
      "     Else (feature 0 > 1.0)\n",
      "      If (feature 5 <= 1.0)\n",
      "       If (feature 7 <= 1.0)\n",
      "        If (feature 0 <= 2.0)\n",
      "         Predict: 2.0\n",
      "        Else (feature 0 > 2.0)\n",
      "         If (feature 2 <= 3.0)\n",
      "          Predict: 1.0\n",
      "         Else (feature 2 > 3.0)\n",
      "          Predict: 2.0\n",
      "       Else (feature 7 > 1.0)\n",
      "        If (feature 6 <= 0.0)\n",
      "         Predict: 2.0\n",
      "        Else (feature 6 > 0.0)\n",
      "         If (feature 7 <= 9.0)\n",
      "          Predict: 2.0\n",
      "         Else (feature 7 > 9.0)\n",
      "          If (feature 3 <= -1.0)\n",
      "           If (feature 1 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 2.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 3 > -1.0)\n",
      "           Predict: 2.0\n",
      "      Else (feature 5 > 1.0)\n",
      "       Predict: 2.0\n",
      "  Else (feature 1 > 3.0)\n",
      "   If (feature 1 <= 8.0)\n",
      "    If (feature 3 <= 0.0)\n",
      "     If (feature 7 <= 3.0)\n",
      "      If (feature 4 <= 1.0)\n",
      "       If (feature 1 <= 5.0)\n",
      "        If (feature 6 <= 0.0)\n",
      "         If (feature 0 <= 3.0)\n",
      "          If (feature 7 <= 1.0)\n",
      "           If (feature 5 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 1.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 0 > 3.0)\n",
      "          If (feature 1 <= 4.0)\n",
      "           If (feature 7 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 0.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 1 > 4.0)\n",
      "           If (feature 2 <= 8.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 8.0)\n",
      "            Predict: 1.0\n",
      "        Else (feature 6 > 0.0)\n",
      "         If (feature 2 <= 0.0)\n",
      "          If (feature 0 <= 1.0)\n",
      "           If (feature 6 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 1.0)\n",
      "           If (feature 6 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 2.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 2 > 0.0)\n",
      "          Predict: 1.0\n",
      "       Else (feature 1 > 5.0)\n",
      "        If (feature 0 <= 11.0)\n",
      "         If (feature 0 <= 9.0)\n",
      "          If (feature 0 <= 8.0)\n",
      "           If (feature 0 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 2.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 8.0)\n",
      "           If (feature 1 <= 6.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 6.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 0 > 9.0)\n",
      "          Predict: 2.0\n",
      "        Else (feature 0 > 11.0)\n",
      "         If (feature 1 <= 6.0)\n",
      "          If (feature 0 <= 16.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 16.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 1 > 6.0)\n",
      "          Predict: 1.0\n",
      "      Else (feature 4 > 1.0)\n",
      "       If (feature 0 <= 4.0)\n",
      "        If (feature 3 <= -1.0)\n",
      "         Predict: 2.0\n",
      "        Else (feature 3 > -1.0)\n",
      "         If (feature 1 <= 4.0)\n",
      "          Predict: 2.0\n",
      "         Else (feature 1 > 4.0)\n",
      "          If (feature 0 <= 2.0)\n",
      "           If (feature 1 <= 5.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 1 > 5.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 2.0)\n",
      "           Predict: 2.0\n",
      "       Else (feature 0 > 4.0)\n",
      "        If (feature 0 <= 7.0)\n",
      "         If (feature 1 <= 4.0)\n",
      "          If (feature 0 <= 5.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 5.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 1 > 4.0)\n",
      "          Predict: 2.0\n",
      "        Else (feature 0 > 7.0)\n",
      "         If (feature 1 <= 4.0)\n",
      "          Predict: 2.0\n",
      "         Else (feature 1 > 4.0)\n",
      "          Predict: 1.0\n",
      "     Else (feature 7 > 3.0)\n",
      "      If (feature 7 <= 4.0)\n",
      "       If (feature 0 <= 6.0)\n",
      "        If (feature 1 <= 7.0)\n",
      "         If (feature 1 <= 6.0)\n",
      "          If (feature 1 <= 4.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 1 > 4.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 1 > 6.0)\n",
      "          If (feature 0 <= 2.0)\n",
      "           If (feature 0 <= 1.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 0 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 2.0)\n",
      "           Predict: 1.0\n",
      "        Else (feature 1 > 7.0)\n",
      "         Predict: 2.0\n",
      "       Else (feature 0 > 6.0)\n",
      "        Predict: 1.0\n",
      "      Else (feature 7 > 4.0)\n",
      "       If (feature 1 <= 6.0)\n",
      "        If (feature 7 <= 9.0)\n",
      "         If (feature 6 <= 3.0)\n",
      "          If (feature 0 <= 2.0)\n",
      "           If (feature 1 <= 4.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 4.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 2.0)\n",
      "           If (feature 7 <= 6.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 6.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 6 > 3.0)\n",
      "          If (feature 0 <= 1.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 0 > 1.0)\n",
      "           If (feature 7 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 7.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 7 > 9.0)\n",
      "         If (feature 1 <= 4.0)\n",
      "          If (feature 7 <= 10.0)\n",
      "           If (feature 0 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 10.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 1 > 4.0)\n",
      "          If (feature 6 <= 3.0)\n",
      "           If (feature 5 <= -1.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 5 > -1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 3.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 1.0\n",
      "       Else (feature 1 > 6.0)\n",
      "        If (feature 0 <= 9.0)\n",
      "         If (feature 0 <= 7.0)\n",
      "          If (feature 5 <= -1.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 5 > -1.0)\n",
      "           If (feature 3 <= -1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 3 > -1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 0 > 7.0)\n",
      "          Predict: 2.0\n",
      "        Else (feature 0 > 9.0)\n",
      "         Predict: 1.0\n",
      "    Else (feature 3 > 0.0)\n",
      "     If (feature 6 <= 0.0)\n",
      "      If (feature 2 <= 2.0)\n",
      "       If (feature 0 <= 3.0)\n",
      "        If (feature 5 <= 1.0)\n",
      "         If (feature 1 <= 4.0)\n",
      "          If (feature 0 <= 2.0)\n",
      "           If (feature 4 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 4 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 2.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 1 > 4.0)\n",
      "          Predict: 2.0\n",
      "        Else (feature 5 > 1.0)\n",
      "         Predict: 2.0\n",
      "       Else (feature 0 > 3.0)\n",
      "        If (feature 1 <= 4.0)\n",
      "         Predict: 2.0\n",
      "        Else (feature 1 > 4.0)\n",
      "         If (feature 3 <= 2.0)\n",
      "          Predict: 2.0\n",
      "         Else (feature 3 > 2.0)\n",
      "          If (feature 0 <= 5.0)\n",
      "           If (feature 5 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 5.0)\n",
      "           Predict: 2.0\n",
      "      Else (feature 2 > 2.0)\n",
      "       If (feature 7 <= 0.0)\n",
      "        If (feature 4 <= 1.0)\n",
      "         If (feature 2 <= 8.0)\n",
      "          If (feature 0 <= 4.0)\n",
      "           If (feature 1 <= 5.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 5.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 4.0)\n",
      "           If (feature 5 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 1.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 2 > 8.0)\n",
      "          If (feature 3 <= 3.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 3 > 3.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 4 > 1.0)\n",
      "         If (feature 5 <= 5.0)\n",
      "          Predict: 2.0\n",
      "         Else (feature 5 > 5.0)\n",
      "          If (feature 2 <= 5.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 2 > 5.0)\n",
      "           If (feature 2 <= 6.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 6.0)\n",
      "            Predict: 2.0\n",
      "       Else (feature 7 > 0.0)\n",
      "        If (feature 2 <= 7.0)\n",
      "         If (feature 7 <= 6.0)\n",
      "          If (feature 7 <= 2.0)\n",
      "           If (feature 0 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 2.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 2.0)\n",
      "           If (feature 1 <= 6.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 6.0)\n",
      "            Predict: 1.0\n",
      "         Else (feature 7 > 6.0)\n",
      "          If (feature 0 <= 1.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 0 > 1.0)\n",
      "           If (feature 7 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 7.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 2 > 7.0)\n",
      "         If (feature 1 <= 5.0)\n",
      "          If (feature 7 <= 10.0)\n",
      "           If (feature 7 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 1.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 7 > 10.0)\n",
      "           If (feature 5 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 2.0)\n",
      "            Predict: 1.0\n",
      "         Else (feature 1 > 5.0)\n",
      "          Predict: 2.0\n",
      "     Else (feature 6 > 0.0)\n",
      "      If (feature 1 <= 5.0)\n",
      "       If (feature 0 <= 4.0)\n",
      "        If (feature 7 <= 1.0)\n",
      "         If (feature 5 <= 5.0)\n",
      "          If (feature 2 <= 3.0)\n",
      "           If (feature 5 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 5 > 2.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 2 > 3.0)\n",
      "           If (feature 0 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 2.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 5 > 5.0)\n",
      "          If (feature 2 <= 2.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 2 > 2.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 7 > 1.0)\n",
      "         If (feature 5 <= 1.0)\n",
      "          If (feature 1 <= 4.0)\n",
      "           If (feature 0 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 3.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 1 > 4.0)\n",
      "           If (feature 2 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 3.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 5 > 1.0)\n",
      "          If (feature 2 <= 7.0)\n",
      "           If (feature 7 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 7.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 2 > 7.0)\n",
      "           If (feature 6 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 6 > 1.0)\n",
      "            Predict: 1.0\n",
      "       Else (feature 0 > 4.0)\n",
      "        If (feature 5 <= 2.0)\n",
      "         If (feature 2 <= 1.0)\n",
      "          Predict: 1.0\n",
      "         Else (feature 2 > 1.0)\n",
      "          If (feature 3 <= 2.0)\n",
      "           Predict: 1.0\n",
      "          Else (feature 3 > 2.0)\n",
      "           If (feature 0 <= 6.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 6.0)\n",
      "            Predict: 1.0\n",
      "        Else (feature 5 > 2.0)\n",
      "         Predict: 2.0\n",
      "      Else (feature 1 > 5.0)\n",
      "       If (feature 6 <= 1.0)\n",
      "        If (feature 2 <= 5.0)\n",
      "         If (feature 5 <= 1.0)\n",
      "          If (feature 0 <= 5.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 0 > 5.0)\n",
      "           If (feature 2 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 3.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 5 > 1.0)\n",
      "          If (feature 5 <= 2.0)\n",
      "           If (feature 1 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 7.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 5 > 2.0)\n",
      "           If (feature 0 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 2.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 2 > 5.0)\n",
      "         If (feature 2 <= 6.0)\n",
      "          If (feature 0 <= 3.0)\n",
      "           If (feature 7 <= 9.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 7 > 9.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 0 > 3.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 2 > 6.0)\n",
      "          If (feature 2 <= 8.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 2 > 8.0)\n",
      "           If (feature 0 <= 2.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 2.0)\n",
      "            Predict: 2.0\n",
      "       Else (feature 6 > 1.0)\n",
      "        If (feature 2 <= 5.0)\n",
      "         If (feature 6 <= 3.0)\n",
      "          If (feature 0 <= 3.0)\n",
      "           If (feature 4 <= 1.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 4 > 1.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 0 > 3.0)\n",
      "           Predict: 1.0\n",
      "         Else (feature 6 > 3.0)\n",
      "          If (feature 2 <= 2.0)\n",
      "           Predict: 2.0\n",
      "          Else (feature 2 > 2.0)\n",
      "           If (feature 1 <= 6.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 6.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 2 > 5.0)\n",
      "         Predict: 2.0\n",
      "   Else (feature 1 > 8.0)\n",
      "    If (feature 0 <= 34.0)\n",
      "     If (feature 0 <= 22.0)\n",
      "      If (feature 1 <= 21.0)\n",
      "       If (feature 2 <= 3.0)\n",
      "        If (feature 0 <= 14.0)\n",
      "         If (feature 0 <= 8.0)\n",
      "          If (feature 6 <= 3.0)\n",
      "           If (feature 0 <= 7.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 0 > 7.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 6 > 3.0)\n",
      "           If (feature 1 <= 13.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 1 > 13.0)\n",
      "            Predict: 2.0\n",
      "         Else (feature 0 > 8.0)\n",
      "          If (feature 0 <= 9.0)\n",
      "           If (feature 6 <= 0.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 6 > 0.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 9.0)\n",
      "           If (feature 2 <= 0.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 0.0)\n",
      "            Predict: 1.0\n",
      "        Else (feature 0 > 14.0)\n",
      "         Predict: 2.0\n",
      "       Else (feature 2 > 3.0)\n",
      "        If (feature 0 <= 7.0)\n",
      "         If (feature 1 <= 9.0)\n",
      "          Predict: 2.0\n",
      "         Else (feature 1 > 9.0)\n",
      "          If (feature 0 <= 5.0)\n",
      "           If (feature 1 <= 13.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 1 > 13.0)\n",
      "            Predict: 2.0\n",
      "          Else (feature 0 > 5.0)\n",
      "           Predict: 1.0\n",
      "        Else (feature 0 > 7.0)\n",
      "         Predict: 1.0\n",
      "      Else (feature 1 > 21.0)\n",
      "       If (feature 0 <= 5.0)\n",
      "        If (feature 1 <= 70.0)\n",
      "         If (feature 1 <= 47.0)\n",
      "          If (feature 2 <= 5.0)\n",
      "           If (feature 2 <= 3.0)\n",
      "            Predict: 2.0\n",
      "           Else (feature 2 > 3.0)\n",
      "            Predict: 1.0\n",
      "          Else (feature 2 > 5.0)\n",
      "           Predict: 2.0\n",
      "         Else (feature 1 > 47.0)\n",
      "          If (feature 2 <= 0.0)\n",
      "           Predict: 1.0\n",
      "          Else (feature 2 > 0.0)\n",
      "           If (feature 0 <= 1.0)\n",
      "            Predict: 1.0\n",
      "           Else (feature 0 > 1.0)\n",
      "            Predict: 2.0\n",
      "        Else (feature 1 > 70.0)\n",
      "         Predict: 2.0\n",
      "       Else (feature 0 > 5.0)\n",
      "        Predict: 1.0\n",
      "     Else (feature 0 > 22.0)\n",
      "      If (feature 1 <= 38.0)\n",
      "       If (feature 1 <= 17.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 1 > 17.0)\n",
      "        Predict: 2.0\n",
      "      Else (feature 1 > 38.0)\n",
      "       Predict: 1.0\n",
      "    Else (feature 0 > 34.0)\n",
      "     Predict: 2.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tree_model.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing error: 0.0194\n"
     ]
    }
   ],
   "source": [
    "test_error = predictions.filter(predictions[\"prediction\"] != predictions[\"Accident_Severity\"]).count() / float(test_data.count())\n",
    "print \"Testing error: {0:.4f}\".format(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "u'requirement failed: LinearSVC only supports binary classification. 3 classes detected in LinearSVC_41e295f443ff72d430d0__labelCol'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-81-b6828b3ab7ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m         labelCol=\"Accident_Severity\")                       # dtov stpec obsahujci cieov atribt (indexy tried)\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# model naume funkciou fit, ktorej predme trnovacie dta\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0msvm_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# presnos klasifikcie vyhodnotme na testovacch dtach pomocou funkcie transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \"\"\"\n\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: u'requirement failed: LinearSVC only supports binary classification. 3 classes detected in LinearSVC_41e295f443ff72d430d0__labelCol'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "vzorka_cela.withColumn(\"Accident_Severity\", when(vzorka_cela[\"Accident_Severity\"] == -1, 2).otherwise(vzorka_cela[\"Accident_Severity\"]))\n",
    "vector_data = VectorAssembler(inputCols=[\"Number_of_Vehicles\", \"Number_of_Casualties\", \"Junction_Detail\", \"Junction_Control\", \"Did_Police_Officer_Attend_Scene_of_Accident\", \"Junction_Location\",\"Skidding_and_Overturning\",\"Hit_Object_off_Carriageway\"],\n",
    "        outputCol=\"features\").transform(vzorka_cela)\n",
    "svm_classifier = LinearSVC(\n",
    "        featuresCol=\"features\",             \n",
    "        labelCol=\"Accident_Severity\")                  \n",
    "\n",
    "svm_model = svm_classifier.fit(training_data)\n",
    "\n",
    "predictions = svm_model.transform(test_data)\n",
    "\n",
    "test_error = predictions.filter(predictions[\"prediction\"] != predictions[\"Accident_Severity\"]).count() / float(test_data.count())\n",
    "print \"Testing error: {0:.4f}\".format(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "u'Field \"class\" does not exist.'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-108-02e72626583b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mml\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstages\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectorAssembler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnormalizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsvc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mevaluator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBinaryClassificationEvaluator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrawPredictionCol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"rawPrediction\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    106\u001b[0m                     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# must be an Estimator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m                     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m                     \u001b[0mtransformers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mindexOfLastEstimator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \"\"\"\n\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m': '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIllegalArgumentException\u001b[0m: u'Field \"class\" does not exist.'"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import Normalizer\n",
    "from pyspark.ml.linalg import Vectors\n",
    "indexer = StringIndexer(inputCol=\"class\", outputCol=\"label\")\n",
    "encoder=OneHotEncoder(inputCol=\"label\", outputCol=\"labelVec\")\n",
    "vectorAssembler = VectorAssembler(inputCols=[\"Number_of_Vehicles\", \"Number_of_Casualties\", \"Junction_Detail\", \"Junction_Control\", \"Did_Police_Officer_Attend_Scene_of_Accident\", \"Junction_Location\",\"Skidding_and_Overturning\",\"Hit_Object_off_Carriageway\"],\n",
    "        outputCol=\"features\")\n",
    "normalizer= Normalizer(inputCol=\"features\",outputCol=\"features_norm\" ,p=1.0)\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "lsvc=LinearSVC(maxIter=10)\n",
    "#vzorka_cela.createOrReplaceTempView(\"df\")\n",
    "#df_two_class=spark.sql(\"select * from df where class in ('Accident_severity' ,'Skidding_and_Overturning') \")\n",
    "#splits=df_two_class.randomSplit(0.8, 0.2)\n",
    "#df_train=splits[0]\n",
    "#df_test=splits[1]\n",
    "from pyspark.ml import Pipeline\n",
    "pipeline=Pipeline(stages=[indexer, encoder, vectorAssembler, normalizer, lsvc])\n",
    "model=pipeline.fit(training_data)\n",
    "prediction= model.transform(training_data)\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\")\n",
    "evaluator.evaluate(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data should be an RDD of LabeledPoint, but got <class 'pyspark.sql.types.Row'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-100-ce887822dbbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmllib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVMWithSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVMModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msvmModel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVMWithSGD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterations\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvmModel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m      \u001b[1;31m#predikovane hodnoty\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpredic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoLocalIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m                                      \u001b[1;31m#predikovana hodnota pretransformovana na list\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\mllib\\classification.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(cls, data, iterations, step, regParam, miniBatchFraction, initialWeights, regType, intercept, validateData, convergenceTol)\u001b[0m\n\u001b[0;32m    551\u001b[0m                                  bool(intercept), bool(validateData), float(convergenceTol))\n\u001b[0;32m    552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_regression_train_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSVMModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitialWeights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\mllib\\regression.py\u001b[0m in \u001b[0;36m_regression_train_wrapper\u001b[1;34m(train_func, modelClass, data, initial_weights)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLabeledPoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data should be an RDD of LabeledPoint, but got %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_weights\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m         \u001b[0minitial_weights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirst\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data should be an RDD of LabeledPoint, but got <class 'pyspark.sql.types.Row'>"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.classification import SVMWithSGD, SVMModel\n",
    "svmModel = SVMWithSGD.train(training_data, iterations=5)\n",
    "\n",
    "prediction = svmModel.predict(test_data.map(lambda p: p.features)) \t#predikovane hodnoty\n",
    "predic = [x for x in prediction.toLocalIterator()]\t\t\t\t\t#predikovana hodnota pretransformovana na list\n",
    "predic = [float(i) for i in predic]\n",
    "labels = test_data.map(lambda p: p.label)\t\t\t\t\t\t\t#povodne hodnoty\n",
    "label = [x for x in labels.toLocalIterator()]\t\t\t\t\t\t#povodne hodnoty pretransformovane na list\n",
    "SVM = matthews_correlation(label, predic)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o994.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 484.0 failed 1 times, most recent failure: Lost task 1.0 in stage 484.0 (TID 40356, localhost, executor driver): java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [1.0,2.0,0.0,-1.0,1.0,0.0,1.0,7.0].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:233)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$4.apply(NaiveBayes.scala:141)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$4.apply(NaiveBayes.scala:141)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$7.apply(NaiveBayes.scala:164)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.trainWithLabelCheck(NaiveBayes.scala:174)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:118)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:78)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:280)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [1.0,2.0,0.0,-1.0,1.0,0.0,1.0,7.0].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:233)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$4.apply(NaiveBayes.scala:141)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$4.apply(NaiveBayes.scala:141)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$7.apply(NaiveBayes.scala:164)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-5093585bf664>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, dataset, params)\u001b[0m\n\u001b[0;32m     62\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m         \u001b[0mjava_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\ml\\wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[1;34m(self, dataset)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \"\"\"\n\u001b[0;32m    261\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[1;32m-> 1133\u001b[1;33m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    317\u001b[0m                 raise Py4JJavaError(\n\u001b[0;32m    318\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 319\u001b[1;33m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[0;32m    320\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                 raise Py4JError(\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o994.fit.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 1 in stage 484.0 failed 1 times, most recent failure: Lost task 1.0 in stage 484.0 (TID 40356, localhost, executor driver): java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [1.0,2.0,0.0,-1.0,1.0,0.0,1.0,7.0].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:233)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$4.apply(NaiveBayes.scala:141)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$4.apply(NaiveBayes.scala:141)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$7.apply(NaiveBayes.scala:164)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.lang.Thread.run(Unknown Source)\r\n\nDriver stacktrace:\r\n\tat org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1499)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1487)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1486)\r\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\r\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1486)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\r\n\tat org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:814)\r\n\tat scala.Option.foreach(Option.scala:257)\r\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:814)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1714)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1669)\r\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1658)\r\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)\r\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:630)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2022)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2043)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2062)\r\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2087)\r\n\tat org.apache.spark.rdd.RDD$$anonfun$collect$1.apply(RDD.scala:936)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\r\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:112)\r\n\tat org.apache.spark.rdd.RDD.withScope(RDD.scala:362)\r\n\tat org.apache.spark.rdd.RDD.collect(RDD.scala:935)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.trainWithLabelCheck(NaiveBayes.scala:174)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:118)\r\n\tat org.apache.spark.ml.classification.NaiveBayes.train(NaiveBayes.scala:78)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:118)\r\n\tat org.apache.spark.ml.Predictor.fit(Predictor.scala:82)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)\r\n\tat java.lang.reflect.Method.invoke(Unknown Source)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:280)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\r\n\tat java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalArgumentException: requirement failed: Naive Bayes requires nonnegative feature values but found [1.0,2.0,0.0,-1.0,1.0,0.0,1.0,7.0].\r\n\tat scala.Predef$.require(Predef.scala:224)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$.requireNonnegativeValues(NaiveBayes.scala:233)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$4.apply(NaiveBayes.scala:141)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$4.apply(NaiveBayes.scala:141)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$7.apply(NaiveBayes.scala:166)\r\n\tat org.apache.spark.ml.classification.NaiveBayes$$anonfun$7.apply(NaiveBayes.scala:164)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:189)\r\n\tat org.apache.spark.util.collection.ExternalSorter$$anonfun$5.apply(ExternalSorter.scala:188)\r\n\tat org.apache.spark.util.collection.AppendOnlyMap.changeValue(AppendOnlyMap.scala:150)\r\n\tat org.apache.spark.util.collection.SizeTrackingAppendOnlyMap.changeValue(SizeTrackingAppendOnlyMap.scala:32)\r\n\tat org.apache.spark.util.collection.ExternalSorter.insertAll(ExternalSorter.scala:194)\r\n\tat org.apache.spark.shuffle.sort.SortShuffleWriter.write(SortShuffleWriter.scala:63)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:96)\r\n\tat org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:53)\r\n\tat org.apache.spark.scheduler.Task.run(Task.scala:108)\r\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:335)\r\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\t... 1 more\r\n"
     ]
    }
   ],
   "source": [
    "#bayes\n",
    "from pyspark.ml .classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    " \n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\",featuresCol=\"features\", labelCol=\"Accident_Severity\")\n",
    " \n",
    "# train the model\n",
    "model = nb.fit(training_data)\n",
    " \n",
    "predictions = model.transform(test_data)\n",
    "#predictions.show()\n",
    " \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Accident_Severity\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing error: 1.0000\n",
      "Root Mean Squared Error (RMSE) on test data = 0.134178\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import GBTRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    " \n",
    "gbt_reg = GBTRegressor(featuresCol=\"features\", labelCol=\"Accident_Severity\", maxIter=10, maxBins=100)\n",
    " \n",
    "# Train model. \n",
    "model = gbt_reg.fit(training_data)\n",
    " \n",
    "# Make predictions.\n",
    "predictions = model.transform(test_data)\n",
    " \n",
    "test_error = predictions.filter(predictions[\"prediction\"] != predictions[\"Accident_Severity\"]).count() / float(test_data.count())\n",
    "print \"Testing error: {0:.4f}\".format(test_error)\n",
    " \n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"Accident_Severity\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g\" % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------------------+---------------+----------------+-------------------------------------------+-----------------+------------------------+--------------------------+--------------------+----------+\n",
      "|Accident_Severity|Number_of_Vehicles|Number_of_Casualties|Junction_Detail|Junction_Control|Did_Police_Officer_Attend_Scene_of_Accident|Junction_Location|Skidding_and_Overturning|Hit_Object_off_Carriageway|            features|prediction|\n",
      "+-----------------+------------------+--------------------+---------------+----------------+-------------------------------------------+-----------------+------------------------+--------------------------+--------------------+----------+\n",
      "|                1|                 1|                   1|              1|               4|                                          1|                3|                       0|                         0|[1.0,1.0,1.0,4.0,...|         0|\n",
      "|                1|                 1|                   4|              0|              -1|                                          1|                0|                       0|                        10|[1.0,4.0,0.0,-1.0...|         1|\n",
      "|                1|                 2|                   1|              3|               4|                                          1|                8|                       0|                         0|[2.0,1.0,3.0,4.0,...|         0|\n",
      "|                1|                 2|                   1|              7|               4|                                          1|                8|                       0|                         0|[2.0,1.0,7.0,4.0,...|         0|\n",
      "|                1|                 2|                   3|              0|              -1|                                          1|                0|                       0|                         0|(8,[0,1,3,4],[2.0...|         1|\n",
      "|                1|                 2|                   3|              9|               4|                                          1|                8|                       5|                         0|[2.0,3.0,9.0,4.0,...|         0|\n",
      "|                1|                 2|                   9|              0|              -1|                                          1|                0|                       5|                         0|[2.0,9.0,0.0,-1.0...|         1|\n",
      "|                1|                 2|                   9|              0|              -1|                                          1|                0|                       5|                         0|[2.0,9.0,0.0,-1.0...|         1|\n",
      "|                1|                 2|                   9|              3|               4|                                          1|                5|                       0|                         0|[2.0,9.0,3.0,4.0,...|         0|\n",
      "|                1|                 2|                  16|              0|              -1|                                          2|                0|                       1|                         0|[2.0,16.0,0.0,-1....|         1|\n",
      "|                1|                 3|                   3|              0|              -1|                                          1|                0|                       0|                         0|(8,[0,1,3,4],[3.0...|         1|\n",
      "|                1|                 3|                   3|              8|               4|                                          1|                8|                       0|                         0|[3.0,3.0,8.0,4.0,...|         0|\n",
      "|                1|                 3|                   4|              0|              -1|                                          1|                0|                       0|                         0|(8,[0,1,3,4],[3.0...|         1|\n",
      "|                1|                 3|                   5|              0|              -1|                                          1|                0|                       0|                         0|(8,[0,1,3,4],[3.0...|         1|\n",
      "|                1|                 4|                   2|              3|               4|                                          1|                5|                       0|                         0|[4.0,2.0,3.0,4.0,...|         0|\n",
      "|                1|                 4|                   3|              3|               4|                                          1|                2|                       0|                         0|[4.0,3.0,3.0,4.0,...|         0|\n",
      "|                1|                 5|                   3|              0|              -1|                                          1|                0|                       0|                         6|[5.0,3.0,0.0,-1.0...|         1|\n",
      "|                1|                 9|                  10|              0|               0|                                          1|                0|                       0|                         0|(8,[0,1,4],[9.0,1...|         1|\n",
      "|                1|                 9|                  10|              0|               0|                                          1|                0|                       1|                         0|(8,[0,1,4,6],[9.0...|         1|\n",
      "|                1|                 1|                   1|              3|               4|                                          1|                5|                       0|                         0|[1.0,1.0,3.0,4.0,...|         0|\n",
      "+-----------------+------------------+--------------------+---------------+----------------+-------------------------------------------+-----------------+------------------------+--------------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "[2.16279465 1.86458322 4.02222398 3.63316833 1.17691968 4.13475981\n",
      " 0.14607569 0.35833626]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans_471cafd5776f37fa25f6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Accident_Severity: int, Number_of_Vehicles: int, Number_of_Casualties: int, Junction_Detail: int, Junction_Control: int, Did_Police_Officer_Attend_Scene_of_Accident: int, Junction_Location: int, Skidding_and_Overturning: int, Hit_Object_off_Carriageway: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(featuresCol=\"features\", k=3, seed=1234)\n",
    "kmeans_model = kmeans.fit(training_data)\n",
    "\n",
    "clusters = kmeans_model.transform(training_data)\n",
    "clusters.show()\n",
    "\n",
    "print(kmeans_model.clusterCenters()[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans_471cafd5776f37fa25f6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[Accident_Severity: int, Number_of_Vehicles: int, Number_of_Casualties: int, Junction_Detail: int, Junction_Control: int, Did_Police_Officer_Attend_Scene_of_Accident: int, Junction_Location: int, Skidding_and_Overturning: int, Hit_Object_off_Carriageway: int]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(kmeans_model, vzorka_cela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-96-19855820b209>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkmeans_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\matplotlib\\pyplot.pyc\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, hold, data, **kwargs)\u001b[0m\n\u001b[0;32m   3473\u001b[0m                          \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3474\u001b[0m                          \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3475\u001b[1;33m                          edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[0;32m   3476\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3477\u001b[0m         \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\matplotlib\\__init__.pyc\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1865\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1867\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1868\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\matplotlib\\axes\\_axes.pyc\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[0;32m   4332\u001b[0m                 \u001b[0moffsets\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moffsets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4333\u001b[0m                 \u001b[0mtransOffset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'transform'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransData\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4334\u001b[1;33m                 \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4335\u001b[0m                 )\n\u001b[0;32m   4336\u001b[0m         \u001b[0mcollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmtransforms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIdentityTransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\matplotlib\\collections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, paths, sizes, **kwargs)\u001b[0m\n\u001b[0;32m    925\u001b[0m         \"\"\"\n\u001b[0;32m    926\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 927\u001b[1;33m         \u001b[0mCollection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    928\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_paths\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_sizes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\matplotlib\\collections.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, edgecolors, facecolors, linewidths, linestyles, capstyle, joinstyle, antialiaseds, offsets, transOffset, norm, cmap, pickradius, hatch, urls, offset_position, zorder, **kwargs)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_uniform_offsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    158\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0moffsets\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m             \u001b[0moffsets\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    160\u001b[0m             \u001b[1;31m# Broadcast (2,) -> (1, 2) but nothing else.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0moffsets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\numpy\\core\\numeric.pyc\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    589\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m     \"\"\"\n\u001b[1;32m--> 591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(clusters, kmeans_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Accident_Severity=1, Number_of_Vehicles=2, Number_of_Casualties=3, Junction_Detail=0, Junction_Control=-1, Did_Police_Officer_Attend_Scene_of_Accident=1, Junction_Location=0, Skidding_and_Overturning=0, Hit_Object_off_Carriageway=0)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vzorka_cela.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-103-224628ecf868>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'features' is not defined"
     ]
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "import urllib\n",
    "\n",
    "# stiahneme si dta z internetu a ulome ich do pracovnho adresra\n",
    "urllib.urlretrieve(\"http://people.tuke.sk/martin.sarnovsky/tsvd/files/iris.csv\", \"iris.csv\")\n",
    "\n",
    "# iris je jednoduch dtov mnoina pre klasifikciu do troch tried\n",
    "# prklady popisuj tri druhy rastln (kosatcov) poda rozmerov ich kvetov (tyry vstupn seln atribty)\n",
    "\n",
    "# natame dta a premapujeme ich na objekty typu Row\n",
    "raw_data = sc.textFile(\"iris.csv\")\n",
    "csv_data = raw_data.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'5.1', u'3.5', u'1.4', u'0.2', u'iris-setosa'],\n",
       " [u'4.9', u'3.0', u'1.4', u'0.2', u'iris-setosa'],\n",
       " [u'4.7', u'3.2', u'1.3', u'0.2', u'iris-setosa'],\n",
       " [u'4.6', u'3.1', u'1.5', u'0.2', u'iris-setosa'],\n",
       " [u'5.0', u'3.6', u'1.4', u'0.2', u'iris-setosa'],\n",
       " [u'5.4', u'3.9', u'1.7', u'0.4', u'iris-setosa'],\n",
       " [u'4.6', u'3.4', u'1.4', u'0.3', u'iris-setosa'],\n",
       " [u'5.0', u'3.4', u'1.5', u'0.2', u'iris-setosa'],\n",
       " [u'4.4', u'2.9', u'1.4', u'0.2', u'iris-setosa'],\n",
       " [u'4.9', u'3.1', u'1.5', u'0.1', u'iris-setosa'],\n",
       " [u'5.4', u'3.7', u'1.5', u'0.2', u'iris-setosa'],\n",
       " [u'4.8', u'3.4', u'1.6', u'0.2', u'iris-setosa'],\n",
       " [u'4.8', u'3.0', u'1.4', u'0.1', u'iris-setosa'],\n",
       " [u'4.3', u'3.0', u'1.1', u'0.1', u'iris-setosa'],\n",
       " [u'5.8', u'4.0', u'1.2', u'0.2', u'iris-setosa'],\n",
       " [u'5.7', u'4.4', u'1.5', u'0.4', u'iris-setosa'],\n",
       " [u'5.4', u'3.9', u'1.3', u'0.4', u'iris-setosa'],\n",
       " [u'5.1', u'3.5', u'1.4', u'0.3', u'iris-setosa'],\n",
       " [u'5.7', u'3.8', u'1.7', u'0.3', u'iris-setosa'],\n",
       " [u'5.1', u'3.8', u'1.5', u'0.3', u'iris-setosa'],\n",
       " [u'5.4', u'3.4', u'1.7', u'0.2', u'iris-setosa'],\n",
       " [u'5.1', u'3.7', u'1.5', u'0.4', u'iris-setosa'],\n",
       " [u'4.6', u'3.6', u'1.0', u'0.2', u'iris-setosa'],\n",
       " [u'5.1', u'3.3', u'1.7', u'0.5', u'iris-setosa'],\n",
       " [u'4.8', u'3.4', u'1.9', u'0.2', u'iris-setosa'],\n",
       " [u'5.0', u'3.0', u'1.6', u'0.2', u'iris-setosa'],\n",
       " [u'5.0', u'3.4', u'1.6', u'0.4', u'iris-setosa'],\n",
       " [u'5.2', u'3.5', u'1.5', u'0.2', u'iris-setosa'],\n",
       " [u'5.2', u'3.4', u'1.4', u'0.2', u'iris-setosa'],\n",
       " [u'4.7', u'3.2', u'1.6', u'0.2', u'iris-setosa'],\n",
       " [u'4.8', u'3.1', u'1.6', u'0.2', u'iris-setosa'],\n",
       " [u'5.4', u'3.4', u'1.5', u'0.4', u'iris-setosa'],\n",
       " [u'5.2', u'4.1', u'1.5', u'0.1', u'iris-setosa'],\n",
       " [u'5.5', u'4.2', u'1.4', u'0.2', u'iris-setosa'],\n",
       " [u'4.9', u'3.1', u'1.5', u'0.1', u'iris-setosa'],\n",
       " [u'5.0', u'3.2', u'1.2', u'0.2', u'iris-setosa'],\n",
       " [u'5.5', u'3.5', u'1.3', u'0.2', u'iris-setosa'],\n",
       " [u'4.9', u'3.1', u'1.5', u'0.1', u'iris-setosa'],\n",
       " [u'4.4', u'3.0', u'1.3', u'0.2', u'iris-setosa'],\n",
       " [u'5.1', u'3.4', u'1.5', u'0.2', u'iris-setosa'],\n",
       " [u'5.0', u'3.5', u'1.3', u'0.3', u'iris-setosa'],\n",
       " [u'4.5', u'2.3', u'1.3', u'0.3', u'iris-setosa'],\n",
       " [u'4.4', u'3.2', u'1.3', u'0.2', u'iris-setosa'],\n",
       " [u'5.0', u'3.5', u'1.6', u'0.6', u'iris-setosa'],\n",
       " [u'5.1', u'3.8', u'1.9', u'0.4', u'iris-setosa'],\n",
       " [u'4.8', u'3.0', u'1.4', u'0.3', u'iris-setosa'],\n",
       " [u'5.1', u'3.8', u'1.6', u'0.2', u'iris-setosa'],\n",
       " [u'4.6', u'3.2', u'1.4', u'0.2', u'iris-setosa'],\n",
       " [u'5.3', u'3.7', u'1.5', u'0.2', u'iris-setosa'],\n",
       " [u'5.0', u'3.3', u'1.4', u'0.2', u'iris-setosa'],\n",
       " [u'7.0', u'3.2', u'4.7', u'1.4', u'iris-versicolor'],\n",
       " [u'6.4', u'3.2', u'4.5', u'1.5', u'iris-versicolor'],\n",
       " [u'6.9', u'3.1', u'4.9', u'1.5', u'iris-versicolor'],\n",
       " [u'5.5', u'2.3', u'4.0', u'1.3', u'iris-versicolor'],\n",
       " [u'6.5', u'2.8', u'4.6', u'1.5', u'iris-versicolor'],\n",
       " [u'5.7', u'2.8', u'4.5', u'1.3', u'iris-versicolor'],\n",
       " [u'6.3', u'3.3', u'4.7', u'1.6', u'iris-versicolor'],\n",
       " [u'4.9', u'2.4', u'3.3', u'1.0', u'iris-versicolor'],\n",
       " [u'6.6', u'2.9', u'4.6', u'1.3', u'iris-versicolor'],\n",
       " [u'5.2', u'2.7', u'3.9', u'1.4', u'iris-versicolor'],\n",
       " [u'5.0', u'2.0', u'3.5', u'1.0', u'iris-versicolor'],\n",
       " [u'5.9', u'3.0', u'4.2', u'1.5', u'iris-versicolor'],\n",
       " [u'6.0', u'2.2', u'4.0', u'1.0', u'iris-versicolor'],\n",
       " [u'6.1', u'2.9', u'4.7', u'1.4', u'iris-versicolor'],\n",
       " [u'5.6', u'2.9', u'3.6', u'1.3', u'iris-versicolor'],\n",
       " [u'6.7', u'3.1', u'4.4', u'1.4', u'iris-versicolor'],\n",
       " [u'5.6', u'3.0', u'4.5', u'1.5', u'iris-versicolor'],\n",
       " [u'5.8', u'2.7', u'4.1', u'1.0', u'iris-versicolor'],\n",
       " [u'6.2', u'2.2', u'4.5', u'1.5', u'iris-versicolor'],\n",
       " [u'5.6', u'2.5', u'3.9', u'1.1', u'iris-versicolor'],\n",
       " [u'5.9', u'3.2', u'4.8', u'1.8', u'iris-versicolor'],\n",
       " [u'6.1', u'2.8', u'4.0', u'1.3', u'iris-versicolor'],\n",
       " [u'6.3', u'2.5', u'4.9', u'1.5', u'iris-versicolor'],\n",
       " [u'6.1', u'2.8', u'4.7', u'1.2', u'iris-versicolor'],\n",
       " [u'6.4', u'2.9', u'4.3', u'1.3', u'iris-versicolor'],\n",
       " [u'6.6', u'3.0', u'4.4', u'1.4', u'iris-versicolor'],\n",
       " [u'6.8', u'2.8', u'4.8', u'1.4', u'iris-versicolor'],\n",
       " [u'6.7', u'3.0', u'5.0', u'1.7', u'iris-versicolor'],\n",
       " [u'6.0', u'2.9', u'4.5', u'1.5', u'iris-versicolor'],\n",
       " [u'5.7', u'2.6', u'3.5', u'1.0', u'iris-versicolor'],\n",
       " [u'5.5', u'2.4', u'3.8', u'1.1', u'iris-versicolor'],\n",
       " [u'5.5', u'2.4', u'3.7', u'1.0', u'iris-versicolor'],\n",
       " [u'5.8', u'2.7', u'3.9', u'1.2', u'iris-versicolor'],\n",
       " [u'6.0', u'2.7', u'5.1', u'1.6', u'iris-versicolor'],\n",
       " [u'5.4', u'3.0', u'4.5', u'1.5', u'iris-versicolor'],\n",
       " [u'6.0', u'3.4', u'4.5', u'1.6', u'iris-versicolor'],\n",
       " [u'6.7', u'3.1', u'4.7', u'1.5', u'iris-versicolor'],\n",
       " [u'6.3', u'2.3', u'4.4', u'1.3', u'iris-versicolor'],\n",
       " [u'5.6', u'3.0', u'4.1', u'1.3', u'iris-versicolor'],\n",
       " [u'5.5', u'2.5', u'4.0', u'1.3', u'iris-versicolor'],\n",
       " [u'5.5', u'2.6', u'4.4', u'1.2', u'iris-versicolor'],\n",
       " [u'6.1', u'3.0', u'4.6', u'1.4', u'iris-versicolor'],\n",
       " [u'5.8', u'2.6', u'4.0', u'1.2', u'iris-versicolor'],\n",
       " [u'5.0', u'2.3', u'3.3', u'1.0', u'iris-versicolor'],\n",
       " [u'5.6', u'2.7', u'4.2', u'1.3', u'iris-versicolor'],\n",
       " [u'5.7', u'3.0', u'4.2', u'1.2', u'iris-versicolor'],\n",
       " [u'5.7', u'2.9', u'4.2', u'1.3', u'iris-versicolor'],\n",
       " [u'6.2', u'2.9', u'4.3', u'1.3', u'iris-versicolor'],\n",
       " [u'5.1', u'2.5', u'3.0', u'1.1', u'iris-versicolor'],\n",
       " [u'5.7', u'2.8', u'4.1', u'1.3', u'iris-versicolor']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data.take(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributes = [\"Number_of_Vehicles\",\n",
    "\t\t\t \"Number_of_Casualties\",\n",
    "\t\t\t \"Junction_Detail\",\n",
    "\t\t\t \"Junction_Control\",\n",
    "\t\t\t \"Did_Police_Officer_Attend_Scene_of_Accident\",\n",
    "\t\t\t \"Junction_Location\",\n",
    "\t\t\t \"Skidding_and_Overturning\",\n",
    "\t\t\t \"Hit_Object_off_Carriageway\",\n",
    "\t\t\t \"Accident_Severity\"]\n",
    "\n",
    "nova_vzorka = vzorka_cela.select(atributes)\n",
    "names2 = nova_vzorka.schema.names\n",
    "\n",
    "for name in names2:\n",
    "\ttype_counts = nova_vzorka.groupBy(name).count()\n",
    "\ttype_counts = type_counts.orderBy([\"count\", name], ascending=[0, 1])\n",
    "\n",
    "\tmoj_list = type_counts.select(name).collect()\n",
    "\tnajcastejsia_hodnota = moj_list[0][0]\n",
    "\n",
    "\tnova_vzorka = nova_vzorka.withColumn(name, when(nova_vzorka[name] == -1,  najcastejsia_hodnota).otherwise(nova_vzorka[name]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set accuracy = 0.0140229635713\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml .classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "vector_data = VectorAssembler(inputCols=[\"Number_of_Vehicles\", \"Number_of_Casualties\", \"Junction_Detail\", \"Junction_Control\", \"Did_Police_Officer_Attend_Scene_of_Accident\", \"Junction_Location\",\"Skidding_and_Overturning\",\"Hit_Object_off_Carriageway\"],\n",
    "        outputCol=\"features\").transform(nova_vzorka) \n",
    "training_data, test_data = vector_data.randomSplit([0.7, 0.3], seed=123)\n",
    "# create the trainer and set its parameters\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\",featuresCol=\"features\", labelCol=\"Accident_Severity\")\n",
    " \n",
    "# train the model\n",
    "model = nb.fit(training_data)\n",
    " \n",
    "predictions = model.transform(test_data)\n",
    "#predictions.show()\n",
    " \n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"Accident_Severity\", predictionCol=\"prediction\",\n",
    "                                              metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test set accuracy = \" + str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-51a962d7b249>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnova_vzorka\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnova_vzorka\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\pyspark\\sql\\dataframe.pyc\u001b[0m in \u001b[0;36mcount\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m         \"\"\"\n\u001b[1;32m--> 427\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    428\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mignore_unicode_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1129\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEND_COMMAND_PART\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1130\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1131\u001b[1;33m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m   1133\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command, retry, binary)\u001b[0m\n\u001b[0;32m    881\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_connection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 883\u001b[1;33m             \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    884\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    885\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_connection_guard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnection\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Spark\\python\\lib\\py4j-0.10.4-src.zip\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36msend_command\u001b[1;34m(self, command)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1028\u001b[1;33m             \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msmart_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1029\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Answer received: {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproto\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRETURN_MESSAGE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\socket.pyc\u001b[0m in \u001b[0;36mreadline\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m                     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_rbufsize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mEINTR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for name in names2:\n",
    "\tx = nova_vzorka.filter(nova_vzorka[name] == -1).count()\n",
    "\tprint(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Number_of_Vehicles=2, Number_of_Casualties=3, Junction_Detail=0, Junction_Control=4, Did_Police_Officer_Attend_Scene_of_Accident=1, Junction_Location=0, Skidding_and_Overturning=0, Hit_Object_off_Carriageway=0, Accident_Severity=1)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nova_vzorka.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_df = nova_vzorka.withColumn(\"Accident_Severity\", when(nova_vzorka[\"Accident_Severity\"] == 1, 0).otherwise(nova_vzorka[\"Accident_Severity\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_df = nova_vzorka.withColumn(\"Accident_Severity\", when(nova_vzorka[\"Accident_Severity\"] == 2, 1).otherwise(nova_vzorka[\"Accident_Severity\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing error: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import LinearSVC\n",
    "SVM_vector_data = VectorAssembler(inputCols=[\"Number_of_Vehicles\", \"Number_of_Casualties\", \"Junction_Detail\", \"Junction_Control\", \"Did_Police_Officer_Attend_Scene_of_Accident\", \"Junction_Location\",\"Skidding_and_Overturning\",\"Hit_Object_off_Carriageway\"],\n",
    "        outputCol=\"features\").transform(SVM_df) \n",
    "SVMtraining_data, SVMtest_data = SVM_vector_data.randomSplit([0.7, 0.3], seed=123)\n",
    "svm_classifier = LinearSVC(\n",
    "        featuresCol=\"features\",             \n",
    "        labelCol=\"Accident_Severity\")                  \n",
    "\n",
    "svm_model = svm_classifier.fit(SVMtraining_data)\n",
    "\n",
    "predictions = svm_model.transform(SVMtest_data)\n",
    "\n",
    "test_error = predictions.filter(predictions[\"prediction\"] != predictions[\"Accident_Severity\"]).count() / float(SVMtest_data.count())\n",
    "print \"Testing error: {0:.4f}\".format(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
